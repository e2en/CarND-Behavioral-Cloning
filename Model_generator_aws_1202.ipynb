{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, MaxPooling2D, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LambdaCallback, Callback\n",
    "from keras.models import model_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "img_dir = '/home/carnd/CarND-Behaviour-Clonning/beta'\n",
    "data_csv_dir = '/home/carnd/CarND-Behaviour-Clonning/beta/'\n",
    "data_csv_name = 'driving_log.csv'\n",
    "\n",
    "col_names = ['center', 'left','right','steering','throttle','brake','speed']\n",
    "\n",
    "training_data = pd.read_csv(data_csv_dir + data_csv_name, names = col_names)\n",
    "training_data.head()\n",
    "line_data = training_data.iloc[[100]].reset_index()\n",
    "numSample = training_data.shape[0]\n",
    "\n",
    "imgLocation = img_dir + training_data['center'][0]\n",
    "\n",
    "steer = np.array(line_data['steering'][0])\n",
    "print(len(training_data))\n",
    "img = mpimg.imread(imgLocation)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(steer)\n",
    "steer = np.asarray(-1 * steer)\n",
    "print(steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = line_data['center'][0]\n",
    "\n",
    "imgLocation = img_dir + str(np.char.strip(path))\n",
    "image = mpimg.imread(imgLocation)\n",
    "\n",
    "lenx = image.shape[0]\n",
    "leny = image.shape[1]\n",
    "#image = cv2.resize(image, (int(leny/2), int(lenx/2)))\n",
    "#image = image = cv2.flip(image, 1)\n",
    "\n",
    "h, w, ch = image.shape\n",
    "\n",
    "pts1 = np.float32([[0, 0], [w, 0], [w, h]])\n",
    "a = 0\n",
    "shift = 100\n",
    "\n",
    "shiftx = rand.randint(- shift, shift)\n",
    "shifty = rand.randint(- shift / 2, shift / 2)\n",
    "\n",
    "pts2 = np.float32([[\n",
    "    0 + rand.randint (- a, a) + shiftx,\n",
    "    0 + rand.randint (- a, a) + shifty,\n",
    "],[\n",
    "    w + rand.randint (- a, a) + shiftx,\n",
    "    0 + rand.randint (- a, a) + shifty,\n",
    "],[\n",
    "    w + rand.randint (- a, a) + shiftx,\n",
    "    h + rand.randint (- a, a) + shifty,\n",
    "]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "image = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "randomLight = 0.25 + np.random.rand() \n",
    "hsv[:,:,2] =  hsv[:,:,2] * randomLight\n",
    "image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "print(len(training_data))    \n",
    "print(image.shape)\n",
    "print(shiftx)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data['steering'].plot.hist(bins=50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_data['steering'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Useless Repeated Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def filter_driving_straight(data_df, hist_items=6):\n",
    "    steering_history = deque([])\n",
    "    \n",
    "    drop_rows=[]\n",
    "    \n",
    "    for idx, row in data_df.iterrows():\n",
    "        # controls = [getattr(row, control) for control in vehicle_controls]\n",
    "        steering = getattr(row, 'steering')\n",
    "        \n",
    "        # record the recent steering history\n",
    "        steering_history.append(steering)\n",
    "        if len(steering_history) > hist_items:\n",
    "            steering_history.popleft()\n",
    "\n",
    "        # if just driving in a straight line continue\n",
    "        if steering_history.count(0.0) == hist_items:\n",
    "            drop_rows.append(idx)\n",
    "\n",
    "    return data_df.drop(data_df.index[drop_rows])\n",
    "\n",
    "#training_data = filter_driving_straight(training_data, 1)\n",
    "\n",
    "training_data['steering'].plot.hist(bins=50)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(training_data['steering'])\n",
    "plt.show()\n",
    "\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "def commaai_model(shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "                input_shape = shape,\n",
    "                output_shape = shape))\n",
    "    \n",
    "    model.add(Convolution2D(16, 8, 8, subsample = (4,4), border_mode = 'same'))\n",
    "    model.add(ELU(()))\n",
    "    \n",
    "    model.add(Convolution2D(32, 5, 5, subsample = (2,2), border_mode = 'same'))\n",
    "    model.add(ELU(()))    \n",
    "\n",
    "    model.add(Convolution2D(64, 5, 5, subsample = (2,2), border_mode = 'same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(ELU(()))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(ELU(()))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def nvidia_model(shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "                input_shape = shape,\n",
    "                output_shape = shape))\n",
    "    \n",
    "    #conv layers with dropout\n",
    "    nb_filters = [24, 36, 48, 64, 64]\n",
    "    kernel_size = [(5, 5), (5, 5), (5, 5), (3, 3), (3, 3)]\n",
    "    same, valid = ('same', 'valid')\n",
    "    padding = [valid, valid, valid, valid, valid]\n",
    "    strides = [(2, 2), (2, 2), (2, 2), (1, 1), (1, 1)]\n",
    "    dropout = 0.5\n",
    "    \n",
    "    for lyr in range(len(nb_filters)):\n",
    "        model.add(Convolution2D(nb_filters[lyr],\n",
    "                                kernel_size[lyr][0],\n",
    "                                kernel_size[lyr][1],\n",
    "                                subsample = strides[lyr],\n",
    "                                border_mode = 'valid',\n",
    "                                activation = 'tanh'))\n",
    "\n",
    "        model.add(Dropout(dropout))\n",
    "                  \n",
    "    #flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #fully connected layers with dropout\n",
    "    neurons = [100, 50, 10]\n",
    "    for l in range(len(neurons)):\n",
    "        model.add(Dense(neurons[l], activation = 'tanh'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "    #logit output - steering angle\n",
    "    model.add(Dense(1, activation = 'tanh', name = 'Out'))\n",
    "    #model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def simple_model(shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    dropout = 0.5\n",
    "    \n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5,\n",
    "                input_shape = shape,\n",
    "                output_shape = shape))\n",
    "    model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "    \n",
    "    model.add(Convolution2D(6, 5, 5, activation = 'relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Convolution2D(16, 5, 5, activation = 'relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Dense(84))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LambdaCallback, Callback\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_train(line_data, i):\n",
    "      \n",
    "    path = line_data['center'][0]\n",
    "    steeringAngle = np.array([[line_data['steering'][0]]])\n",
    "    steer = steeringAngle[0] \n",
    "        \n",
    "    if i%4 == 1:\n",
    "        path = line_data['left'][0]\n",
    "        steeringAngle = np.array([[line_data['steering'][0]]])\n",
    "        steer = steeringAngle[0] + 0.3\n",
    "        \n",
    "    if i%4 == 2:\n",
    "        path = line_data['right'][0]\n",
    "        steeringAngle = np.array([[line_data['steering'][0]]])\n",
    "        steer = steeringAngle[0] - 0.3\n",
    "        \n",
    "    imgLocation = img_dir + str(np.char.strip(path))\n",
    "    image = mpimg.imread(imgLocation)\n",
    "    \n",
    "    if i%4 == 3:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steer = -1 * steer\n",
    "    \n",
    "    if np.random.randint(2) == 2:\n",
    "        #right curve: positive increase\n",
    "        #left curve: negative decrease\n",
    "\n",
    "        h, w, ch = image.shape\n",
    "\n",
    "        pts1 = np.float32([[0, 0], [w, 0], [w, h]])\n",
    "        a = 0\n",
    "        shift = 100\n",
    "\n",
    "        shiftx = rand.randint(- shift, shift)\n",
    "        shifty = rand.randint(- shift / 100, shift / 100)\n",
    "\n",
    "        pts2 = np.float32([[\n",
    "            0 + rand.randint (- a, a) + shiftx,\n",
    "            0 + rand.randint (- a, a) + shifty,\n",
    "        ],[\n",
    "            w + rand.randint (- a, a) + shiftx,\n",
    "            0 + rand.randint (- a, a) + shifty,\n",
    "        ],[\n",
    "            w + rand.randint (- a, a) + shiftx,\n",
    "            h + rand.randint (- a, a) + shifty,\n",
    "        ]])\n",
    "\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        image = cv2.warpAffine(img, M, (w, h))\n",
    "        steer = shiftx * 0.00625 + steer\n",
    "        \n",
    "    if np.random.randint(2) == 1:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        randomLight = 0.25 + np.random.rand() \n",
    "        hsv[:,:,2] =  hsv[:,:,2] * randomLight\n",
    "        image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return image, steer \n",
    "\n",
    "def preprocess_val(line_data):\n",
    "    path = line_data['center'][0]\n",
    "    steeringAngle = np.array([[line_data['steering'][0]]])\n",
    "    steer = steeringAngle[0] \n",
    "    imgLocation = img_dir + str(np.char.strip(path))\n",
    "    image = mpimg.imread(imgLocation)\n",
    "    return image, steer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generateBatch_Train(data, batchSize = 32):\n",
    "    \n",
    "    while True:\n",
    "        batchX = np.zeros((batchSize, 160, 320, 3),dtype = float)\n",
    "        batchy = np.zeros((batchSize, 1),dtype=float)\n",
    "        \n",
    "        for i_batch in range(batchSize):\n",
    "            \n",
    "            i_line = np.random.randint(len(data))\n",
    "            line_data = data.iloc[[i_line]].reset_index()\n",
    "            \n",
    "            X, y = preprocess_train(line_data, i_batch)\n",
    "            \n",
    "            batchX[i_batch] = X\n",
    "            batchy[i_batch] = y\n",
    "        \n",
    "        yield batchX, batchy\n",
    "\n",
    "def generateBatch_Val(data):\n",
    "    \n",
    "    while True:\n",
    "        batchX = np.zeros((1, 160, 320, 3),dtype = float)\n",
    "        batchy = np.zeros((1, 1),dtype=float)\n",
    "        \n",
    "        i_line = np.random.randint(len(data))\n",
    "        line_data = data.iloc[[i_line]].reset_index()\n",
    "        \n",
    "        X, y = preprocess_val(line_data)\n",
    "        \n",
    "        #X = X.reshape(1, X.shape[0], X.shape[1], X.shape[2])\n",
    "        #y = np.array([[y]])\n",
    "        batchX[0] = X\n",
    "        batchy[0] = y\n",
    "        \n",
    "        yield batchX, batchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = (160, 320, 3)\n",
    "#model = commaai_model(shape)\n",
    "model = nvidia_model(shape)\n",
    "#model = simple_model(shape)\n",
    "\n",
    "training_data = shuffle(training_data)\n",
    "train_data, val_data = sklearn.model_selection.train_test_split(training_data, test_size=0.2, random_state=0)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "\n",
    "numTimes = 1\n",
    "numEpoch = 5\n",
    "samplesPerEpoch = len(train_data) * 8\n",
    "nbValSamples = len(val_data)\n",
    "val_best = 999\n",
    "\n",
    "for time in range(numTimes):\n",
    "    \n",
    "    trainGenerator = generateBatch_Train(train_data, batchSize = 256)\n",
    "    validGenerator = generateBatch_Val(val_data)\n",
    "    \n",
    "    #history = model.fit(X_train, y_train, nb_epoch=numEpoch, validation_split=0.2)\n",
    "    history = model.fit_generator(trainGenerator, \n",
    "                                  samples_per_epoch = samplesPerEpoch, \n",
    "                                  nb_epoch = numEpoch, \n",
    "                                  validation_data = validGenerator, \n",
    "                                  nb_val_samples = nbValSamples)\n",
    "\n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    if val_loss < val_best:\n",
    "        val_best = val_loss\n",
    "        fileModelJSON = 'model_best_1202_v12.json'\n",
    "        fileWeights = 'model_best_1202_v12.h5'\n",
    "        save_model(fileModelJSON,fileWeights)\n",
    "        \n",
    "    print('Time: ', time + 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
